---
title: 'Password Cracking'
#subtitle: Waiting for neural networks to train is always the most annoying time and even more ennoying  when the datasets are large. Indeed, but changing #the optimization algorithm may bring a significant change in speed as well as accuracu for the deep learning model training.
# Summary for listings and search engines
#summary: 
# Link this post with a project
projects: []

# Date published
date: "2020-05-30T00:00:00Z"

# Date updated
#lastmod: "2020-12-13T00:00:00Z"

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: false

# Featured image
# Place an image named `featured.jpg/png` in this page's folder and customize its options here.
#image:
#  caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/CpkOjOcXdUY)'
#  focal_point: ""
#  placement: 2
#  preview_only: false

authors:
- admin

tags:
- Deep learning
- Generative Adversarial Network 
- Long Short Term Memory
- Password Cracking
- Probabilistic Context-Free Grammar


---
There are several algorithms that decrypt the hashes of the passwords obtained from other password databases leaks. These algorithms generate passwords, hashes them using the encryption algorithm, and then compare the hash with the hashes present in the database; if the hash matches, Bingo! We got the password corresponding to that hash; otherwise, keep generating and comparing passwords.


[Read more here](https://gargrohan138.medium.com/password-cracking-1b14e0844404) 